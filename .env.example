# copy to .env and set your key
GEMINI_API_KEY=AIzaSyDaLMM-N3gXWEJUZ_8FYvLB_ujI9sqc94I
# Embeddings MUST have the "models/" prefix
EMBEDDING_MODEL=models/text-embedding-004

# If you want local generation with your installed Ollama model:
USE_LOCAL_LLM=true
LOCAL_MODEL_NAME=deepseek-coder:6.7b
LOCAL_EMBEDDING_MODEL=nomic-embed-text
# (Optional) If you want to keep Gemini generation instead:
# USE_LOCAL_LLM=false
# GENERATION_MODEL=gemini-1.5-flash


# Generation and embeddings (Gemini)
GENERATION_MODEL=gemini-1.5-flash-002
EMBEDDING_MODEL=models/text-embedding-004 # must include "models/"
    # safe, public, fast